{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0bbaff8",
   "metadata": {},
   "source": [
    "## This notebook contain work for the ecoSPECS challenge at European Summer of Code 2025. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1afba0",
   "metadata": {},
   "source": [
    "### Making use of an NLP Model, MarianMTModel from the HuggingFace model hub, i translated the trial datasets, which consist of nine(9) .docx file into english, while i know this does not partend to the task given, i just did this in other to grasp the larger context of what the project is and also found it to be a valuable step in grasping the intent behind each document. This deeper comprehension helped me appreciate the structure, language, and goals of the specification and documentation process, which in turn informed my approach to the actual challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dee3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from docx.oxml.text.paragraph import CT_P\n",
    "from docx.text.paragraph import Paragraph\n",
    "from docx import Document\n",
    "import spacy\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from docx.oxml.table import CT_Tbl\n",
    "from docx.table import Table\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "model_name = 'Helsinki-NLP/opus-mt-de-en'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "def translate_german_to_english(text):\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated = model.generate(**inputs)\n",
    "    english_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "    return english_text\n",
    "\n",
    "def translate_text_sentence_based(text):\n",
    "\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "    translated_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if sentence:\n",
    "            translated = translate_german_to_english(sentence)\n",
    "            translated_sentences.append(translated)\n",
    "    return \" \".join(translated_sentences)\n",
    "\n",
    "def translate_paragraph_with_formatting(paragraph, translated_doc):\n",
    "\n",
    "    new_para = translated_doc.add_paragraph()\n",
    "    new_para.style = paragraph.style\n",
    "\n",
    "    for run in paragraph.runs:\n",
    "        run_text = run.text.strip()\n",
    "        if run_text:\n",
    "            translated_text = translate_text_sentence_based(run_text)\n",
    "            new_run = new_para.add_run(translated_text)\n",
    "\n",
    "            new_run.bold = run.bold\n",
    "            new_run.italic = run.italic\n",
    "            new_run.underline = run.underline\n",
    "            new_run.font.name = run.font.name\n",
    "            new_run.font.size = run.font.size\n",
    "\n",
    "def translate_docx_file_preserve_styles(input_path, output_path):\n",
    "    doc = Document(input_path)\n",
    "    translated_doc = Document()\n",
    "\n",
    "    if translated_doc.paragraphs:\n",
    "        p = translated_doc.paragraphs[0]._element\n",
    "        translated_doc._element.body.remove(p)\n",
    "\n",
    "    for element in doc.element.body:\n",
    "        if isinstance(element, CT_P):  \n",
    "            para = Paragraph(element, doc)\n",
    "            if para.text.strip():\n",
    "                translate_paragraph_with_formatting(para, translated_doc)\n",
    "            else:\n",
    "                translated_doc.add_paragraph(\"\")\n",
    "\n",
    "        elif isinstance(element, CT_Tbl): \n",
    "            table = Table(element, doc)\n",
    "\n",
    "            \n",
    "            new_table = translated_doc.add_table(rows=len(table.rows), cols=len(table.columns))\n",
    "            new_table.style = table.style\n",
    "\n",
    "            for i, row in enumerate(table.rows):\n",
    "                for j, cell in enumerate(row.cells):\n",
    "                    german_text = cell.text.strip()\n",
    "                    translated_text = translate_text_sentence_based(german_text) if german_text else \"\"\n",
    "                    target_cell = new_table.cell(i, j)\n",
    "                    \n",
    "                    \n",
    "                    for p in target_cell.paragraphs:\n",
    "                        p.clear()\n",
    "                    target_cell.text = translated_text\n",
    "\n",
    "    translated_doc.save(output_path)\n",
    "    print(f\"Translation completed! Saved to: {output_path}\")\n",
    "\n",
    "\n",
    "def translate_multiple_docx_files(input_folder, output_folder):\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".docx\"):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, f\"{filename[:-5]}_translated.docx\")\n",
    "            print(f\"Translating: {filename}\")\n",
    "            translate_docx_file_preserve_styles(input_path, output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce17606",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "translate_multiple_docx_files(\"data\", \"data/translated_docs\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
