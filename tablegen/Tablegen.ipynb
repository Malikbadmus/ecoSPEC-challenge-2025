{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dt18tNN_53w"
      },
      "source": [
        "# Solution to ecoSPEC-challenge Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oELpitfUAF__"
      },
      "source": [
        "Due to limited compute resources, I will be using Google Colab to run inferences. The following code is from my main.py, but I am running the mistralai/Mistral-Nemo-Instruct-2407 model through the Hugging Face Inference API instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/https://github.com/Malikbadmus/ecoSPEC-challenge-2025/blob/main/tablegen/Tablegen.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3UQbPZIgmlU",
        "outputId": "349f6712-bc82-49cd-a040-fdc320490363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ GPU is available!\n",
            "GPU Name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"✅ GPU is available!\")\n",
        "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"❌ No GPU available. Go to Runtime > Change runtime type and select GPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMEPO_X5gpI5",
        "outputId": "cb6055fd-17c2-4f1d-83d4-3d7dccb20b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.1)\n",
            "Requirement already satisfied: docx2pdf in /usr/local/lib/python3.11/dist-packages (0.1.8)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from docx2pdf) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx\n",
        "!pip install docx2pdf\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "qLp9f0ne72qE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from typing import List, Optional\n",
        "\n",
        "import torch\n",
        "import requests\n",
        "from docx import Document\n",
        "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMWvlTt37zP3"
      },
      "outputs": [],
      "source": [
        "class TableFiller:\n",
        "    def __init__(self, model_name: str = \"mistralai/Mistral-Nemo-Instruct-2407\", api_key: str = \"\"):\n",
        "        print(f\"Using Hugging Face API model: {model_name}\")\n",
        "        self.api_key = api_key\n",
        "        self.model_name = model_name\n",
        "        self.url = f\"https://api-inference.huggingface.co/models/{model_name}\"\n",
        "        self.headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
        "\n",
        "    def format_prompt(self, user_prompt: str, row_headers: Optional[List[str]] = None,\n",
        "                      column_headers: Optional[List[str]] = None, num_rows: int = 5, num_cols: int = 3) -> str:\n",
        "        prompt = f\"Generate table content for: {user_prompt}\\n\"\n",
        "        if row_headers:\n",
        "            prompt += f\"Row headers: {', '.join(row_headers)}\\n\"\n",
        "        if column_headers:\n",
        "            prompt += f\"Column headers: {', '.join(column_headers)}\\n\"\n",
        "        if not row_headers and not column_headers:\n",
        "            prompt += f\"Generate a {num_rows}x{num_cols} table with appropriate values.\\n\"\n",
        "        prompt += \"\\nReturn ONLY a JSON array of arrays.\"\n",
        "        return prompt\n",
        "\n",
        "    def call_hf_api(self, prompt: str) -> list:\n",
        "        payload = {\"inputs\": prompt}\n",
        "        try:\n",
        "            response = requests.post(self.url, headers=self.headers, json=payload)\n",
        "            response.raise_for_status()\n",
        "            output = response.json()\n",
        "\n",
        "            text = output[0][\"generated_text\"]\n",
        "            print(\"Raw API Output:\\n\", text)\n",
        "\n",
        "            match = re.search(r'(\\[\\s*\\[.*?\\]\\s*\\])', text, re.DOTALL)\n",
        "            if match:\n",
        "                json_str = match.group(1)\n",
        "                parsed = json.loads(json_str)\n",
        "                return parsed\n",
        "            else:\n",
        "                print(\"Could not extract valid JSON array.\")\n",
        "                return []\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(\"Request failed:\", e)\n",
        "        except Exception as e:\n",
        "            print(\"Unexpected error:\", e)\n",
        "        return []\n",
        "\n",
        "    def generate_table(self, prompt: str, row_headers: Optional[List[str]] = None,\n",
        "                   column_headers: Optional[List[str]] = None,\n",
        "                   num_rows: int = 5, num_cols: int = 3) -> List[List[str]]:\n",
        "\n",
        "\n",
        "        full_prompt = f\"Generate a table with the following rows: {', '.join(row_headers)} and columns: {', '.join(column_headers)}. Return only the JSON array of arrays. No comments, no explanation.\"\n",
        "\n",
        "        print(\"Prompt sent to API:\\n\", full_prompt)\n",
        "\n",
        "        result = self.call_hf_api(full_prompt)\n",
        "        print(\"Raw API Output:\\n\", result)\n",
        "\n",
        "        return (result)\n",
        "\n",
        "\n",
        "    def save_to_docx(self, table_data: List[List[str]], file_path: str,\n",
        "                 intro_text: Optional[str] = None, title: Optional[str] = None):\n",
        "        doc = Document()\n",
        "        if title:\n",
        "            heading = doc.add_heading(title, level=1)\n",
        "            heading.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
        "        if intro_text:\n",
        "            doc.add_paragraph(intro_text)\n",
        "\n",
        "\n",
        "        max_cols = max(len(row) for row in table_data)\n",
        "        rows = len(table_data)\n",
        "\n",
        "        table = doc.add_table(rows=rows, cols=max_cols)\n",
        "        table.style = 'Table Grid'\n",
        "\n",
        "        for i, row in enumerate(table_data):\n",
        "            for j in range(max_cols):\n",
        "                value = str(row[j]) if j < len(row) else \"\"\n",
        "                table.cell(i, j).text = value\n",
        "\n",
        "        doc.save(file_path)\n",
        "        print(f\"Saved table to {file_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVyPOQof1xp-",
        "outputId": "723cfcbc-d8cc-4f87-d5c1-98289b06dcbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Hugging Face API model: mistralai/Mistral-Nemo-Instruct-2407\n",
            "Prompt sent to API:\n",
            " Generate a table with the following rows: Apple, Banana, Orange, Grapes, Strawberry and columns: Calories, Sugar (g), Vitamin C (mg). Return only the JSON array of arrays. No comments, no explanation.\n",
            "Raw API Output:\n",
            " Generate a table with the following rows: Apple, Banana, Orange, Grapes, Strawberry and columns: Calories, Sugar (g), Vitamin C (mg). Return only the JSON array of arrays. No comments, no explanation. [\n",
            " [\"Calories\", \"Sugar (g)\", \"Vitamin C (mg)\"],\n",
            " [\"Apple\", 52, 4.2, 4.6],\n",
            " [\"Banana\", 89, 12.2, 8.7],\n",
            " [\"Orange\", 39, 7.0, 53.2],\n",
            " [\"Grapes\", 104, 16.25, 1.2],\n",
            " [\"Strawberry\", 49, 4.89, 58.8]\n",
            "]\n",
            "Raw API Output:\n",
            " [['Calories', 'Sugar (g)', 'Vitamin C (mg)'], ['Apple', 52, 4.2, 4.6], ['Banana', 89, 12.2, 8.7], ['Orange', 39, 7.0, 53.2], ['Grapes', 104, 16.25, 1.2], ['Strawberry', 49, 4.89, 58.8]]\n",
            "Saved table to fruit_nutrition.docx\n"
          ]
        }
      ],
      "source": [
        "api_key = \"\"\n",
        "model = \"mistralai/Mistral-Nemo-Instruct-2407\"\n",
        "\n",
        "table_filler = TableFiller(model_name=model, api_key=api_key)\n",
        "\n",
        "prompt = \"Nutritional information of common fruits\"\n",
        "row_headers = [\"Apple\", \"Banana\", \"Orange\", \"Grapes\", \"Strawberry\"]\n",
        "column_headers = [\"Calories\", \"Sugar (g)\", \"Vitamin C (mg)\"]\n",
        "\n",
        "table_data = table_filler.generate_table(\n",
        "    prompt,\n",
        "    row_headers=row_headers,\n",
        "    column_headers=column_headers\n",
        ")\n",
        "\n",
        "table_filler.save_to_docx(\n",
        "    table_data,\n",
        "    file_path=\"fruit_nutrition.docx\",\n",
        "    intro_text=\"This table contains nutritional information of common fruits.\",\n",
        "    title=\"Fruit Nutrition Table\"\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
